# llm_client.py
import os
import json
import google.generativeai as genai
import traceback

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ---
try:
    # –ü—ã—Ç–∞–µ–º—Å—è –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –∫–ª—é—á –∏–∑ config.py
    from config import API_KEY
except ImportError:
    API_KEY = "AIzaSyBlaBFxx2cwnKpmG-OR9Nu32OUPvM1Zeis"

# !!! –í–ê–ñ–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –∏ –±—ã—Å—Ç—Ä—É—é –º–æ–¥–µ–ª—å !!!
# gemini-2.5-pro –µ—â–µ –Ω–µ –≤—ã—à–ª–∞ –ø—É–±–ª–∏—á–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É–µ–º 1.5-flash
CHAT_MODEL_NAME = 'gemini-2.5-pro'

# --- –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø ---
is_api_ready = False
chat_model = None

try:
    # –ï—Å–ª–∏ –∫–ª—é—á –Ω–µ –≤ –∫–æ–Ω—Ñ–∏–≥–µ, –∏—â–µ–º –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
    if "–í–ê–®_" in API_KEY or not API_KEY:
        API_KEY = os.environ.get("GEMINI_API_KEY", "")

    if API_KEY:
        genai.configure(api_key=API_KEY)
        chat_model = genai.GenerativeModel(CHAT_MODEL_NAME)
        is_api_ready = True
        print(f">>> LLM Client: –ú–æ–¥–µ–ª—å {CHAT_MODEL_NAME} –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ.")
    else:
        print(">>> LLM Client: API Key –Ω–µ –Ω–∞–π–¥–µ–Ω.")
except Exception as e:
    print(f"Init Error: {e}")


# ======================================================
# 1. –§–£–ù–ö–¶–ò–ò –ê–ì–ï–ù–¢–ê (–ü–õ–ê–ù–ò–†–û–í–ê–ù–ò–ï –ò –í–´–ü–û–õ–ù–ï–ù–ò–ï)
# ======================================================

def get_strategic_plan(user_request: str) -> dict:
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∑–∞–ø—Ä–æ—Å –∏ —Å–æ–∑–¥–∞–µ—Ç –ø–æ—à–∞–≥–æ–≤—ã–π –ø–ª–∞–Ω —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON.
    """
    if not is_api_ready or chat_model is None:
        return {"error": "API Key not set", "steps": []}

    prompt = f"""
    –¢—ã ‚Äî Tech Lead –∏ –ê—Ä—Ö–∏—Ç–µ–∫—Ç–æ—Ä –ü–û.
    –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî —Ä–∞–∑–±–∏—Ç—å –∑–∞–¥–∞—á—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–∞ –ª–æ–≥–∏—á–µ—Å–∫–∏–µ —ç—Ç–∞–ø—ã —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏.

    –ó–ê–î–ê–ß–ê –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø: {user_request}

    –¢–†–ï–ë–û–í–ê–ù–ò–Ø:
    1. –í–µ—Ä–Ω–∏ –æ—Ç–≤–µ—Ç –°–¢–†–û–ì–û –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON.
    2. –ù–µ –ø–∏—à–∏ –Ω–∏–∫–∞–∫–æ–≥–æ –∫–æ–¥–∞, —Ç–æ–ª—å–∫–æ –ø–ª–∞–Ω –¥–µ–π—Å—Ç–≤–∏–π.
    3. –†–∞–∑–±–µ–π –∑–∞–¥–∞—á—É –Ω–∞ 3-6 —à–∞–≥–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä: –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞, –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö, –õ–æ–≥–∏–∫–∞, UI).

    –§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê (JSON):
    {{
        "project_name": "–ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞",
        "steps": [
            "–®–∞–≥ 1: –°–æ–∑–¥–∞—Ç—å –±–∞–∑–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ñ–∞–π–ª–æ–≤...",
            "–®–∞–≥ 2: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –º–æ–¥–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö...",
            "–®–∞–≥ 3: –ù–∞—Å—Ç—Ä–æ–∏—Ç—å –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—é..."
        ]
    }}
    """

    try:
        response = chat_model.generate_content(prompt)
        text = response.text
        # –û—á–∏—Å—Ç–∫–∞ –æ—Ç Markdown (–µ—Å–ª–∏ –º–æ–¥–µ–ª—å –≤–µ—Ä–Ω—É–ª–∞ ```json ... ```)
        text = text.replace("```json", "").replace("```", "").strip()
        return json.loads(text)
    except Exception as e:
        print(f"Plan Error: {e}")
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∞–≤–∞—Ä–∏–π–Ω—ã–π –ø–ª–∞–Ω, —á—Ç–æ–±—ã –ø—Ä–æ–≥—Ä–∞–º–º–∞ –Ω–µ —É–ø–∞–ª–∞
        return {
            "project_name": "Task Execution",
            "steps": [f"–í—ã–ø–æ–ª–Ω–∏—Ç—å –∑–∞–¥–∞—á—É: {user_request}"]
        }


def execute_step(current_step: str, full_task: str, rag_context: list) -> str:
    """
    –ü–∏—à–µ—Ç –∫–æ–¥ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —à–∞–≥–∞, —É—á–∏—Ç—ã–≤–∞—è –Ω–∞–π–¥–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç (RAG).
    """
    if not is_api_ready or chat_model is None:
        return "Error: API Key not set."

    # –°–æ–±–∏—Ä–∞–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è
    parts = [
        "–¢—ã ‚Äî AI Developer (Cursor Agent). –ú—ã —Ä–∞–∑—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø—Ä–æ–µ–∫—Ç –ø–æ—ç—Ç–∞–ø–Ω–æ.",
        f"–ì–õ–ê–í–ù–ê–Ø –¶–ï–õ–¨ –ü–†–û–ï–ö–¢–ê: {full_task}",
        f"–¢–ï–ö–£–©–ê–Ø –ó–ê–î–ê–ß–ê (–≠–¢–ê–ü): {current_step}",
        "",
        "–ò–ù–°–¢–†–£–ö–¶–ò–Ø:",
        "1. –ù–∞–ø–∏—à–∏ –∏–ª–∏ –∏–∑–º–µ–Ω–∏ —Ñ–∞–π–ª—ã, –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¢–û–õ–¨–ö–û –¥–ª—è —ç—Ç–æ–≥–æ —ç—Ç–∞–ø–∞.",
        "2. –ï—Å–ª–∏ –Ω—É–∂–Ω–æ —Å–æ–∑–¥–∞—Ç—å —Ñ–∞–π–ª, –∏—Å–ø–æ–ª—å–∑—É–π —Ñ–æ—Ä–º–∞—Ç:",
        "### FILE: path/to/filename.ext",
        "–∫–æ–¥...",
        "### END_FILE",
        "3. –í–ê–ñ–ù–û:",
        "   - –í—Å–µ–≥–¥–∞ —É–∫–∞–∑—ã–≤–∞–π –ø–æ–ª–Ω—ã–π –ø—É—Ç—å (–Ω–∞–ø—Ä–∏–º–µ—Ä: app/models.py).",
        "   - –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π ```python –∏–ª–∏ ``` –≤–Ω—É—Ç—Ä–∏ –±–ª–æ–∫–∞ ### FILE.",
        "   - –ü–∏—à–∏ –ø–æ–ª–Ω–æ—Å—Ç—å—é —Ä–∞–±–æ—á–∏–π –∫–æ–¥."
    ]

    # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ RAG (—á—Ç–æ–±—ã –∞–≥–µ–Ω—Ç –≤–∏–¥–µ–ª —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∫–æ–¥)
    if rag_context:
        parts.append("\n=== üóÑÔ∏è –ö–û–ù–¢–ï–ö–°–¢ –ü–†–û–ï–ö–¢–ê (–°—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∫–æ–¥) ===")
        parts.append("(–ò—Å–ø–æ–ª—å–∑—É–π —ç—Ç–æ—Ç –∫–æ–¥, —á—Ç–æ–±—ã –ø–æ–Ω–∏–º–∞—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏ –Ω–µ –¥—É–±–ª–∏—Ä–æ–≤–∞—Ç—å —Ñ–∞–π–ª—ã)")
        for chunk in rag_context:
            parts.append(f"{chunk}\n---")

    prompt = "\n".join(parts)

    try:
        response = chat_model.generate_content(prompt)
        return response.text
    except Exception as e:
        traceback.print_exc()
        return f"Error executing step: {e}"


# ======================================================
# 2. –§–£–ù–ö–¶–ò–ò –û–ë–´–ß–ù–û–ì–û –ß–ê–¢–ê (HELPER METHODS)
# ======================================================

def get_chat_response(full_prompt: str) -> str:
    """–ë–∞–∑–æ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è (–¥–ª—è –ø—Ä–æ—Å—Ç—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤)."""
    if not is_api_ready or chat_model is None:
        return "‚ö†Ô∏è –û—à–∏–±–∫–∞: API Key –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω."

    try:
        response = chat_model.generate_content(full_prompt)
        return response.text
    except Exception as e:
        traceback.print_exc()
        return f"API Error: {e}"


def build_context_prompt(user_message: str, context_files: dict, active_file_data: tuple, rag_context: list) -> str:
    """
    –°–æ–±–∏—Ä–∞–µ—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è –æ–±—ã—á–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞ —á–∞—Ç–∞ (–Ω–µ –∞–≥–µ–Ω—Ç–Ω–æ–≥–æ).
    –ü—Ä–∏–Ω–∏–º–∞–µ—Ç –∫–æ—Ä—Ç–µ–∂ (–∏–º—è_—Ñ–∞–π–ª–∞, –∫–æ–¥).
    """
    active_filename = "None"
    active_code = ""

    # –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∞
    try:
        if active_file_data and isinstance(active_file_data, tuple):
            active_filename = active_file_data[0]
            active_code = active_file_data[1]
    except:
        pass

    parts = [
        "–¢—ã ‚Äî –ü–æ–º–æ—â–Ω–∏–∫ –ø–æ –∫–æ–¥—É.",
        "–û—Ç–≤–µ—á–∞–π –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –∏—Å–ø–æ–ª—å–∑—É—è –∫–æ–Ω—Ç–µ–∫—Å—Ç.",
        f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–µ–π—á–∞—Å —Å–º–æ—Ç—Ä–∏—Ç —Ñ–∞–π–ª: {active_filename}"
    ]

    if rag_context:
        parts.append("\n=== RAG Context ===")
        for chunk in rag_context:
            parts.append(f"{chunk}\n---")

    if active_code:
        parts.append(f"\n=== Active File Content ({active_filename}) ===\n{active_code}")

    parts.append(f"\n=== –í–û–ü–†–û–° ===\n{user_message}")

    return "\n".join(parts)


def get_code_review(code: str) -> str:
    """–ó–∞–ø—Ä–æ—Å –Ω–∞ —Ä–µ–≤—å—é –∫–æ–¥–∞."""
    prompt = (
        "–í—ã–ø–æ–ª–Ω–∏ Code Review —ç—Ç–æ–≥–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞. "
        "–ù–∞–π–¥–∏ –±–∞–≥–∏, —É—è–∑–≤–∏–º–æ—Å—Ç–∏ –∏ –ø—Ä–æ–±–ª–µ–º—ã —Å–æ —Å—Ç–∏–ª–µ–º. "
        "–ë—É–¥—å –∫—Ä–∞—Ç–æ–∫.\n\n"
        f"{code}"
    )
    return get_chat_response(prompt)